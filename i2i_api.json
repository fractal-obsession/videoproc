{
  "4": {
    "inputs": {
      "ckpt_name": "albedobaseXL_v13.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "6": {
    "inputs": {
      "text": "positive prompt",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "test",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "10": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 685728929340616,
      "steps": 100,
      "cfg": 20,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 60,
      "end_at_step": 100,
      "return_with_leftover_noise": "disable",
      "model": [
        "4",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "51",
        0
      ]
    },
    "class_type": "KSamplerAdvanced"
  },
  "17": {
    "inputs": {
      "samples": [
        "10",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "19": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "17",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "50": {
    "inputs": {
      "image": "example.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage"
  },
  "51": {
    "inputs": {
      "pixels": [
        "53",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "53": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1,
      "image": [
        "50",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels"
  },
  "54": {
    "inputs": {
      "width": 720,
      "height": 720,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  }
}
